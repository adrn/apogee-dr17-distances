{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['APOGEE_CACHE_PATH'] = \"/mnt/ceph/users/apricewhelan/apogee-test/\"\n",
    "os.environ['JOAQUIN_CACHE_PATH'] = \"/mnt/ceph/users/apricewhelan/projects/joaquin/cache\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=Warning) \n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import pathlib\n",
    "_path = str(pathlib.Path('../').resolve())\n",
    "if _path not in sys.path:\n",
    "    sys.path.append(_path)\n",
    "\n",
    "import corner\n",
    "from astropy.io import fits\n",
    "import astropy.coordinates as coord\n",
    "import astropy.table as at\n",
    "import astropy.units as u\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "from joaquin.data import JoaquinData\n",
    "from joaquin.config import (dr, root_cache_path, \n",
    "                            neighborhood_size, block_size)\n",
    "from joaquin.plot import simple_corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = pathlib.Path(f'../cache/{dr}').resolve()\n",
    "cache_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "plot_path = pathlib.Path('../plot') / dr\n",
    "plot_path = plot_path.resolve()\n",
    "plot_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the first two notebooks (1- and 2-) to set up the necessary files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_data = JoaquinData.read('parent-sample')\n",
    "parent_data = parent_data[np.all(np.isfinite(parent_data.X), axis=1)]\n",
    "\n",
    "global_spec_mask = np.load(cache_path / 'global_spec_bad_mask.npy')\n",
    "\n",
    "neighborhood_idx = np.load(cache_path / 'good_parent_neighborhood_indices.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_stars = parent_data.stars[parent_data.stars_mask]\n",
    "# parent_d, *_ = parent_data.get_Xy(spec_mask_thresh=1.)  # disable spec mask\n",
    "# assert len(parent_stars) == parent_d['X'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in neighborhood_idx[131:]:\n",
    "    data = parent_data[idx]\n",
    "    \n",
    "    spec_bad_mask = (data.spec_bad_masks.sum(axis=0) / len(data.stars)) > 0.25\n",
    "    patched_data = data.patch_spec()\n",
    "    patched_data.spec_bad_masks = None\n",
    "    patched_data = patched_data.mask_spec_pixels(spec_bad_mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp, _ = data.get_X('spec')\n",
    "npix_fixed = (tmp[:, ~global_spec_mask] == 0).sum()\n",
    "\n",
    "tmp_patched, _ = patched_data.get_X('spec')\n",
    "assert (tmp_patched == 0).sum() == 0\n",
    "\n",
    "print(f\"{npix_fixed} pixels patched, ~{npix_fixed/tmp.shape[0]:.0f} pixels patched per star\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: could make 2d images showing before/after patching. Turn masked pixels into hot pixels so they are very obvious in the before pics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowpass_data = patched_data.lowpass_filter_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp, _ = lowpass_data.get_X('spec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = coord.Distance(parallax=lowpass_data.stars['GAIAEDR3_PARALLAX']*u.mas, allow_negative=True)\n",
    "MG = lowpass_data.stars['GAIAEDR3_PHOT_G_MEAN_MAG'] - dist.distmod.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# ax.imshow(tmp[MG.argsort()] - np.mean(tmp, axis=0), origin='lower', \n",
    "#           vmin=np.percentile(tmp.ravel(), 1),\n",
    "#           vmax=np.percentile(tmp.ravel(), 99))\n",
    "\n",
    "# diff = tmp[MG.argsort()] - np.mean(tmp, axis=0)\n",
    "diff = tmp[lowpass_data.stars['LOGG'].argsort()] - np.mean(tmp, axis=0)\n",
    "ax.imshow(diff, origin='lower', \n",
    "          vmin=np.percentile(diff.ravel(), 1),\n",
    "          vmax=np.percentile(diff.ravel(), 99),\n",
    "          cmap='RdBu')\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "ax.set_xlabel('wavelength')\n",
    "ax.set_ylabel('stars, ordered by LOGG')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: make some before/after 1D plots showing that the low-pass filter is actually doing something. show full spectrum and zoomed window, before/after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lim in [False, 'zoom', 'zoomer']:\n",
    "#     plt.figure(figsize=(16, 5))\n",
    "#     plt.plot(parent_data._X_wvln, subX[i], marker='', drawstyle='steps-mid')\n",
    "#     plt.plot(parent_data._X_wvln, subX_patched[i], marker='', drawstyle='steps-mid')\n",
    "#     plt.plot(parent_data._X_wvln, new_ln_flux, marker='', drawstyle='steps-mid')\n",
    "#     if lim == 'zoom':\n",
    "#         plt.xlim(16000, 16500)\n",
    "#     elif lim == 'zoomer':\n",
    "#         plt.xlim(16150, 16220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try running the rest of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training sample is the full neighborhood, with some parallax and S/N cuts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_data = lowpass_data.mask_spec_pixels()\n",
    "masked_data = lowpass_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = masked_data[:block_size]\n",
    "zone2 = masked_data[block_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(block.stars['TEFF'],\n",
    "            block.stars['LOGG'], \n",
    "            c=block.stars['M_H'],\n",
    "            s=4, vmin=-1.5, vmax=0.5)\n",
    "\n",
    "plt.scatter(zone2.stars['TEFF'],\n",
    "            zone2.stars['LOGG'], \n",
    "            s=2, zorder=-10)\n",
    "\n",
    "plt.xlim(8500, 3000)\n",
    "plt.ylim(5.5, -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (\n",
    "    (block.stars['SNR'] > 100) &\n",
    "    (block.stars['GAIAEDR3_PARALLAX_ERROR'] < 0.1)\n",
    ")\n",
    "\n",
    "zone2_train_mask = (\n",
    "    (zone2.stars['SNR'] > 100) &\n",
    "    (zone2.stars['GAIAEDR3_PARALLAX_ERROR'] < 0.1)\n",
    ")\n",
    "\n",
    "# TODO: add RUWE selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joaquin.crossval import get_Kfold_indices\n",
    "\n",
    "def get_Kfold_indices(N, K, train_mask=None, rng=None):\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    idx = np.arange(N)\n",
    "    rng.shuffle(idx)\n",
    "    \n",
    "    # We may want to impose other criteria on the training \n",
    "    # sample, like high S/N or small parallax error\n",
    "    if train_mask is not None:\n",
    "        train_subset_idx = np.argwhere(train_mask).ravel()\n",
    "    else:\n",
    "        train_subset_idx = idx\n",
    "\n",
    "    batch_size = N // K\n",
    "    train_batches = []\n",
    "    test_batches = []\n",
    "    for k in range(K):\n",
    "        if k == K-1:\n",
    "            test_batch = idx[k*batch_size:]\n",
    "        else:\n",
    "            test_batch = idx[k*batch_size:(k+1)*batch_size]\n",
    "\n",
    "        train_batch = idx[~np.isin(idx, test_batch) & \n",
    "                          np.isin(idx, train_subset_idx)]\n",
    "        \n",
    "        # adds the stars that don't meet quality cuts to \n",
    "        # appear in the training sample:\n",
    "        test_batch = idx[~np.isin(idx, train_batch)]\n",
    "            \n",
    "        test_batches.append(test_batch)\n",
    "        train_batches.append(train_batch)\n",
    "    \n",
    "    assert np.all(np.array([len(train_batches[i]) + len(test_batches[i])\n",
    "                            for i in range(len(train_batches))]) == N)\n",
    "\n",
    "    return train_batches, test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "train_idxs, test_idxs = get_Kfold_indices(len(block.stars), K=8, rng=rng, \n",
    "                                          train_mask=train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phot_names = [\n",
    "    'GAIAEDR3_PHOT_G_MEAN_MAG', \n",
    "    'GAIAEDR3_PHOT_BP_MEAN_MAG',\n",
    "    'GAIAEDR3_PHOT_RP_MEAN_MAG', \n",
    "    'J', 'H', 'K', \n",
    "    'w1mpro', 'w2mpro'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "train_idx = train_idxs[i]\n",
    "test_idx = test_idxs[i]\n",
    "\n",
    "test_block = block[test_idx]\n",
    "test_X, _ = test_block.get_X(phot_names=phot_names)\n",
    "test_y = test_block.stars['GAIAEDR3_PARALLAX']\n",
    "test_y_ivar = 1 / test_block.stars['GAIAEDR3_PARALLAX_ERROR'] ** 2\n",
    "\n",
    "train_block = block[train_idx]\n",
    "block_train_X, idx_map = train_block.get_X(phot_names=phot_names)\n",
    "block_train_y = train_block.stars['GAIAEDR3_PARALLAX']\n",
    "block_train_y_ivar = 1 / train_block.stars['GAIAEDR3_PARALLAX_ERROR'] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2, idx_map2 = zone2.get_X()\n",
    "# y2 = zone2.stars['GAIAEDR3_PARALLAX']\n",
    "# y_ivar2 = 1 / zone2.stars['GAIAEDR3_PARALLAX_ERROR'] ** 2\n",
    "\n",
    "# X = np.vstack((block_train_X, X2[zone2_train_mask]))\n",
    "# y = np.concatenate((block_train_y, y2[zone2_train_mask]))\n",
    "# y_ivar = np.concatenate((block_train_y_ivar, y_ivar2[zone2_train_mask]))\n",
    "\n",
    "# for k in idx_map:\n",
    "#     assert np.all(idx_map[k] == idx_map2[k])\n",
    "\n",
    "# HACK: TESTING\n",
    "X = block_train_X\n",
    "y = block_train_y\n",
    "y_ivar = block_train_y_ivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = simple_corner(X[:, idx_map['phot']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = simple_corner(X[:, idx_map['lsf']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-0.5, 5, 256)\n",
    "plt.hist(y, bins=bins);\n",
    "\n",
    "plt.hist(test_block.stars['GAIAEDR3_PARALLAX'], \n",
    "         bins=bins);\n",
    "\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from joaquin.logger import logger\n",
    "\n",
    "\n",
    "class Joaquin:\n",
    "\n",
    "    def __init__(self, X, y, y_ivar, idx_map, frozen=None):\n",
    "        self.X = X \n",
    "        self.y = y\n",
    "        self.y_ivar = y_ivar\n",
    "\n",
    "        # Currently, stores parameter names and shapes\n",
    "        self._param_info = {}\n",
    "\n",
    "        # duh\n",
    "        self._param_info['parallax_zpt'] = 1\n",
    "\n",
    "        # the inv-var of the prior on the spectral components in beta\n",
    "        self._param_info['L2_ivar'] = 1\n",
    "\n",
    "        # linear coefficients (in the exp argument)\n",
    "        self._param_info['beta'] = self.X.shape[1]\n",
    "        \n",
    "        self.idx_map = idx_map\n",
    "        if 'spec' in idx_map:\n",
    "            L2_slice = self.idx_map['spec']\n",
    "        else:\n",
    "            L2_slice = np.ones(self.X.shape[1], dtype=bool)\n",
    "        self.L2_slice = L2_slice\n",
    "\n",
    "        if frozen is None:\n",
    "            frozen = {}\n",
    "        self.frozen = frozen\n",
    "\n",
    "    def unpack_pars(self, par_list):\n",
    "        i = 0\n",
    "        par_dict = {}\n",
    "        for key, par_len in self._param_info.items():\n",
    "            if key in self.frozen:\n",
    "                par_dict[key] = self.frozen[key]\n",
    "            else:\n",
    "                par_dict[key] = np.array(par_list[i:i+par_len])\n",
    "                if len(par_dict[key]) == 1:  # HORRIBLE\n",
    "                    par_dict[key] = par_dict[key][0]\n",
    "\n",
    "                i += par_len\n",
    "\n",
    "        return par_dict\n",
    "\n",
    "    def pack_pars(self, par_dict):\n",
    "        parvec = []\n",
    "        for i, k in enumerate(self._param_info):\n",
    "            if k not in self.frozen:\n",
    "                parvec.append(par_dict[k])\n",
    "        return np.concatenate(parvec)\n",
    "\n",
    "    def init_beta(self, parallax_zpt=None, L2_ivar=None):\n",
    "        parallax_zpt = self.frozen.get('parallax_zpt', parallax_zpt)\n",
    "        L2_ivar = self.frozen.get('L2_ivar', L2_ivar)\n",
    "\n",
    "        if parallax_zpt is None or L2_ivar is None:\n",
    "            raise ValueError('todo')\n",
    "\n",
    "        y = self.y + parallax_zpt\n",
    "        plx_mask = y > (3 / np.sqrt(self.y_ivar))  # 3 sigma\n",
    "\n",
    "        X = self.X[plx_mask]\n",
    "        y = y[plx_mask]\n",
    "        y_ivar = self.y_ivar[plx_mask]\n",
    "\n",
    "        ln_plx_ivar = y**2 * y_ivar\n",
    "        ln_y = np.log(y)\n",
    "\n",
    "        XT_Cinv = X.T * ln_plx_ivar\n",
    "        XT_Cinv_X = np.dot(XT_Cinv, X)\n",
    "        XT_Cinv_X[np.diag_indices(X.shape[1])] += L2_ivar\n",
    "\n",
    "        beta = np.linalg.solve(XT_Cinv_X, np.dot(XT_Cinv, ln_y))\n",
    "        return beta\n",
    "\n",
    "    def chi(self, parallax_zpt, L2_ivar, beta):\n",
    "        y = self.y + parallax_zpt\n",
    "        model_ln_plx = np.dot(self.X, beta)\n",
    "        model_y = np.exp(model_ln_plx)\n",
    "        resid = y - model_y\n",
    "        return resid * np.sqrt(self.y_ivar)\n",
    "\n",
    "    def ln_likelihood(self, parallax_zpt, L2_ivar, beta):\n",
    "        y = self.y + parallax_zpt\n",
    "        model_ln_plx = np.dot(self.X, beta)\n",
    "        model_y = np.exp(model_ln_plx)\n",
    "        resid = y - model_y\n",
    "\n",
    "        ll = -0.5 * np.sum(resid**2 * self.y_ivar)\n",
    "        ll_grad = np.dot(self.X.T,\n",
    "                         model_y * self.y_ivar * resid)\n",
    "\n",
    "        return ll, ll_grad\n",
    "\n",
    "    def ln_prior(self, parallax_zpt, L2_ivar, beta):\n",
    "        lp = - 0.5 * L2_ivar * np.sum(beta[self.L2_slice] ** 2)\n",
    "        lp_grad = np.zeros_like(beta)\n",
    "        lp_grad[self.L2_slice] = - L2_ivar * beta[self.L2_slice]\n",
    "        return lp, lp_grad\n",
    "\n",
    "    def neg_ln_posterior(self, parallax_zpt, L2_ivar, beta):\n",
    "        ll, ll_grad = self.ln_likelihood(parallax_zpt, L2_ivar, beta)\n",
    "        lp, lp_grad = self.ln_prior(parallax_zpt, L2_ivar, beta)\n",
    "        logger.log(0, f'objective function evaluation: ll={ll}, lp={lp}')\n",
    "        return - (ll + lp), - (ll_grad + lp_grad)\n",
    "\n",
    "    def __call__(self, p):\n",
    "        par_dict = self.unpack_pars(p)\n",
    "        return self.neg_ln_posterior(**par_dict)\n",
    "\n",
    "    def optimize(self, init=None, **minimize_kwargs):\n",
    "        \"\"\"\n",
    "        To set the maximum number of function evaluations, pass:\n",
    "\n",
    "            options={'maxfun': ...}\n",
    "\n",
    "        \"\"\"\n",
    "        if init is None:\n",
    "            init = {}\n",
    "\n",
    "        init.setdefault('parallax_zpt', 0.)\n",
    "        init.setdefault('L2_ivar', 1.)\n",
    "\n",
    "        if 'beta' not in init:\n",
    "            init['beta'] = self.init_beta(**init)\n",
    "\n",
    "        x0 = self.pack_pars(init)\n",
    "\n",
    "        minimize_kwargs.setdefault('method', 'L-BFGS-B')\n",
    "        if minimize_kwargs['method'] == 'L-BFGS-B':\n",
    "            minimize_kwargs.setdefault('options', {'maxfun': 1024})\n",
    "\n",
    "        res = minimize(\n",
    "            self,\n",
    "            x0=x0,\n",
    "            jac=True,\n",
    "            **minimize_kwargs)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in [1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "#     frozen = {'L2_ivar': val, \n",
    "#               'parallax_zpt': -0.03}  # MAGIC NUMBERs\n",
    "#     joa = Joaquin(block_train_X, \n",
    "#                   block_train_y, \n",
    "#                   block_train_y_ivar, \n",
    "#                   idx_map, \n",
    "#                   frozen=frozen)\n",
    "#     res = joa.optimize(options={'maxiter': 1000})\n",
    "#     print(joa(res.x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See previous cell\n",
    "frozen = {'L2_ivar': 1e-3, \n",
    "          'parallax_zpt': -0.03}  # MAGIC NUMBERs\n",
    "\n",
    "joa = Joaquin(X[:4096], y[:4096], y_ivar[:4096], \n",
    "              idx_map, frozen=frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = joa.optimize(options={'maxiter': 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pars = joa.unpack_pars(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(fit_pars['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_plx = np.exp(np.dot(X, fit_pars['beta'])) - fit_pars['parallax_zpt']\n",
    "chi = (pred_plx - y) * np.sqrt(y_ivar)\n",
    "\n",
    "test_pred_plx = np.exp(np.dot(test_X, fit_pars['beta'])) - fit_pars['parallax_zpt']\n",
    "test_chi = (test_pred_plx - test_y) * np.sqrt(test_y_ivar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(y,\n",
    "        pred_plx,\n",
    "        marker='o', ls='none', mew=0, ms=1., alpha=0.4)\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(ax.get_xlim())\n",
    "ax.set_xlabel('Gaia plx')\n",
    "ax.set_ylabel('Joaquin plx')\n",
    "\n",
    "_grid = np.linspace(-0.5, 1.5, 10)\n",
    "ax.plot(_grid, _grid, marker='', \n",
    "        zorder=-10, color='#aaaaaa')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(y,\n",
    "        chi,\n",
    "        marker='o', ls='none', mew=0, ms=1.5, alpha=0.75)\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(-8, 8)\n",
    "ax.set_xlabel('Gaia plx')\n",
    "ax.set_ylabel(r'$\\chi$')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(test_block.stars['GAIAEDR3_PARALLAX'],\n",
    "        test_pred_plx,\n",
    "        marker='o', ls='none', mew=0, ms=1.5, alpha=0.75)\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(ax.get_xlim())\n",
    "ax.set_xlabel('Gaia plx')\n",
    "ax.set_ylabel('Joaquin plx')\n",
    "\n",
    "_grid = np.linspace(-0.5, 1.5, 10)\n",
    "ax.plot(_grid, _grid, marker='', \n",
    "        zorder=-10, color='#aaaaaa')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(test_block.stars['GAIAEDR3_PARALLAX'],\n",
    "        test_chi,\n",
    "        marker='o', ls='none', mew=0, ms=1.5, alpha=0.75)\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(-8, 8)\n",
    "ax.set_xlabel('Gaia plx')\n",
    "ax.set_ylabel(r'$\\chi$')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ccc in [chi, test_chi]:\n",
    "    plt.figure()\n",
    "    plt.hist(ccc, bins=np.linspace(-5, 5, 64));\n",
    "    for x in np.percentile(ccc, [16, 84]):\n",
    "        plt.axvline(x, color='tab:blue')\n",
    "\n",
    "    plt.axvline(1, linestyle='--', color='#666666')\n",
    "    plt.axvline(-1, linestyle='--', color='#666666')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_K_batches(data, K, frozen=None, optimize_kw=None):\n",
    "    \"\"\"\n",
    "    TODO: could take a pool argument and parallelize the loop below\n",
    "    \"\"\"\n",
    "\n",
    "    if frozen is None:\n",
    "        frozen = dict()\n",
    "\n",
    "    if optimize_kw is None:\n",
    "        optimize_kw = dict()\n",
    "    optimize_kw.setdefault('options', {'maxiter': 1_000})  # TODO: make this bigger\n",
    "\n",
    "    train_batches, test_batches = get_Kfold_indices(clean_stars, K=K)\n",
    "\n",
    "    batch_fit_pars = []\n",
    "    batch_res = []\n",
    "    test_loss = []\n",
    "    for k, (train_batch, test_batch) in enumerate(zip(train_batches, test_batches)):\n",
    "        joa = Joaquin(data[train_batch], frozen=frozen)\n",
    "        test_joa = Joaquin(data[test_batch], frozen=frozen)\n",
    "        \n",
    "        res = joa.optimize(**optimize_kw)\n",
    "        fit_pars = joa.unpack_pars(res.x)\n",
    "\n",
    "        batch_res.append(res)\n",
    "        batch_fit_pars.append(fit_pars)\n",
    "        \n",
    "        # evaluate the fit model on the test batch\n",
    "        test_loss.append(test_joa.neg_ln_posterior(**fit_pars)[0])\n",
    "\n",
    "    return batch_fit_pars, batch_res, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def cross_validate_hyperpars(data, K, frozen, **kwargs):\n",
    "    kwargs = kwargs.copy()\n",
    "    kwargs.setdefault('method', 'powell')\n",
    "    \n",
    "    # HACK / BAD: hardcoded names\n",
    "    assert len(frozen) == 1\n",
    "    if 'L2_ivar' in frozen:\n",
    "        xval_par = 'parallax_zpt'\n",
    "        kwargs.setdefault('x0', -0.03)\n",
    "        \n",
    "    elif 'parallax_zpt' in frozen:\n",
    "        xval_par = 'L2_ivar'\n",
    "        kwargs.setdefault('x0', 1e2)\n",
    "    \n",
    "    def objective(p):\n",
    "        pars = frozen.copy()\n",
    "        pars[xval_par] = p\n",
    "        fit_pars, reses, losses = fit_K_batches(data, K, frozen=pars)\n",
    "        return sum(losses)\n",
    "    \n",
    "    res = minimize(objective, **kwargs)\n",
    "    return {xval_par: float(res.x)}, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adrian conda base",
   "language": "python",
   "name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
