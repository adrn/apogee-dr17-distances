{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues:\n",
    "- The missing data are being filled in wrong. The NUFFT will pull missing regions down to 1, but we should really use PCA to patch the missing data. So, iteratively: low-pass filter, PCA patch the previously missing data, iterate.\n",
    "- Lowpass filter is whack and could be checked against Barnett/DFM\n",
    "- The LSF housekeeping data is super hacky - do we need something better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['APOGEE_CACHE_PATH'] = \"/mnt/ceph/users/apricewhelan/apogee-test/\"\n",
    "\n",
    "import sys\n",
    "import pathlib\n",
    "_path = str(pathlib.Path('../').resolve())\n",
    "if _path not in sys.path:\n",
    "    sys.path.append(_path)\n",
    "\n",
    "import corner\n",
    "from astropy.io import fits\n",
    "import astropy.coordinates as coord\n",
    "import astropy.table as at\n",
    "import astropy.units as u\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from joaquin import Joaquin\n",
    "from joaquin.design_matrix import JoaquinData\n",
    "from joaquin.config import phot_names, dr, Kfold_K\n",
    "from joaquin.logger import logger\n",
    "from joaquin.plot import simple_corner, phot_to_label\n",
    "\n",
    "from gala.mpl_style import hesperia, laguna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = pathlib.Path(f'../cache/{dr}').resolve()\n",
    "cache_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = at.Table.read(cache_path / 'parent-sample.fits')\n",
    "\n",
    "parent_stars = parent[\n",
    "    (parent['LOGG'] < 2.2) & \n",
    "    (parent['LOGG'] > 1.5) &\n",
    "    (parent['TEFF'] > 3500) &\n",
    "    (parent['TEFF'] < 5000)]\n",
    "\n",
    "# HACK: subselect for speed\n",
    "np.random.seed(42)\n",
    "idx = np.random.choice(len(parent_stars), size=4096, replace=False)\n",
    "parent_stars = parent_stars[idx]\n",
    "\n",
    "len(parent_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "bins = (np.linspace(3000, 7500, 128),\n",
    "        np.linspace(0, 5.5, 128))\n",
    "ax.hist2d(parent['TEFF'], parent['LOGG'],\n",
    "          bins=bins, norm=mpl.colors.LogNorm(),\n",
    "          cmap='magma_r')\n",
    "\n",
    "ax.plot(parent_stars['TEFF'],\n",
    "        parent_stars['LOGG'],\n",
    "        ls='none', marker='o', mew=0, ms=3., \n",
    "        color='tab:blue', alpha=0.75)\n",
    "\n",
    "ax.set_ylim(5.5, 0)\n",
    "ax.set_xlim(7500, 3000)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, star_mask = JoaquinData.from_stars(\n",
    "    parent_stars, cache_path=cache_path, \n",
    "    spec_mask_thresh=0.2)  # MAGIC NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(data._spec_mask_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_stars = parent_stars[star_mask]\n",
    "clean_data = data[star_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training sample from parent sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = ((clean_stars['SNR'] > 100) &\n",
    "              (clean_stars['GAIAEDR3_PARALLAX_ERROR'] < 0.1))\n",
    "# TODO: add RUWE selection\n",
    "\n",
    "check_mask = (clean_stars['GAIAEDR3_PARALLAX'] / clean_stars['GAIAEDR3_PARALLAX_ERROR']) > 20\n",
    "\n",
    "train_mask.sum(), len(clean_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stars = clean_stars[train_mask]\n",
    "train_data = clean_data[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_stars['GAIAEDR3_PARALLAX'], \n",
    "         bins=np.linspace(-0.5, 2, 128));\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import downscale_local_mean\n",
    "\n",
    "for sort_by in ['TEFF']:\n",
    "    tmp_X, *_ = train_data.get_sub_Xy('spec')\n",
    "    tmp_X = downscale_local_mean(\n",
    "        tmp_X[train_stars[sort_by].argsort()],\n",
    "        (4, 4))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 7.5))\n",
    "    ax.imshow(tmp_X, \n",
    "              origin='lower', \n",
    "              vmin=np.percentile(tmp_X, 5), \n",
    "              vmax=np.percentile(tmp_X, 95))\n",
    "    # ax.set_aspect(2)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_X, *_ = train_data.get_sub_Xy('spec')\n",
    "_, vals, _ = np.linalg.svd(tmp_X, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vals)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-4, 1e2)\n",
    "plt.axvline(min(tmp_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Kfold_indices(stars, K, rng=None):\n",
    "    \n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "        \n",
    "    idx = np.arange(len(stars))\n",
    "    rng.shuffle(idx)\n",
    "    \n",
    "    batch_size = len(stars) // K\n",
    "    train_batches = []\n",
    "    test_batches = []\n",
    "    for k in range(K):\n",
    "        if k == K-1:\n",
    "            batch = idx[k*batch_size:]\n",
    "        else:\n",
    "            batch = idx[k*batch_size:(k+1)*batch_size]\n",
    "            \n",
    "        test_batches.append(batch)\n",
    "        train_batches.append(idx[~np.isin(idx, batch)])\n",
    "        \n",
    "    assert np.all(np.array([len(train_batches[i]) + len(test_batches[i]) \n",
    "                            for i in range(len(train_batches))]) == len(stars))\n",
    "    \n",
    "    return train_batches, test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_K_batches(data, K, frozen=None, optimize_kw=None):\n",
    "    \"\"\"\n",
    "    TODO: could take a pool argument and parallelize the loop below\n",
    "    \"\"\"\n",
    "\n",
    "    if frozen is None:\n",
    "        frozen = dict()\n",
    "\n",
    "    if optimize_kw is None:\n",
    "        optimize_kw = dict()\n",
    "    optimize_kw.setdefault('options', {'maxiter': 1_000})  # TODO: make this bigger\n",
    "\n",
    "    train_batches, test_batches = get_Kfold_indices(clean_stars, K=K)\n",
    "\n",
    "    batch_fit_pars = []\n",
    "    batch_res = []\n",
    "    test_loss = []\n",
    "    for k, (train_batch, test_batch) in enumerate(zip(train_batches, test_batches)):\n",
    "        joa = Joaquin(data[train_batch], frozen=frozen)\n",
    "        test_joa = Joaquin(data[test_batch], frozen=frozen)\n",
    "        \n",
    "        res = joa.optimize(**optimize_kw)\n",
    "        fit_pars = joa.unpack_pars(res.x)\n",
    "\n",
    "        batch_res.append(res)\n",
    "        batch_fit_pars.append(fit_pars)\n",
    "        \n",
    "        # evaluate the fit model on the test batch\n",
    "        test_loss.append(test_joa.neg_ln_posterior(**fit_pars)[0])\n",
    "\n",
    "    return batch_fit_pars, batch_res, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def cross_validate_hyperpars(data, K, frozen, **kwargs):\n",
    "    kwargs = kwargs.copy()\n",
    "    kwargs.setdefault('method', 'powell')\n",
    "    \n",
    "    # HACK / BAD: hardcoded names\n",
    "    assert len(frozen) == 1\n",
    "    if 'L2_ivar' in frozen:\n",
    "        xval_par = 'parallax_zpt'\n",
    "        kwargs.setdefault('x0', -0.03)\n",
    "        \n",
    "    elif 'parallax_zpt' in frozen:\n",
    "        xval_par = 'L2_ivar'\n",
    "        kwargs.setdefault('x0', 1e2)\n",
    "    \n",
    "    def objective(p):\n",
    "        pars = frozen.copy()\n",
    "        pars[xval_par] = p\n",
    "        fit_pars, reses, losses = fit_K_batches(data, K, frozen=pars)\n",
    "        return sum(losses)\n",
    "    \n",
    "    res = minimize(objective, **kwargs)\n",
    "    return {xval_par: float(res.x)}, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cross_validate_hyperpars(clean_data, K=8, \n",
    "                               frozen={'parallax_zpt': -0.03})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joa = Joaquin(clean_data, frozen=frozen)\n",
    "beta = joa.init_beta()\n",
    "pars = joa.unpack_pars(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f joa.ln_likelihood joa.ln_likelihood(**pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_param(param, joa, batches, frozen=):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen = {'L2_ivar': 1e-1, \n",
    "          'parallax_zpt': -0.03}  # MAGIC NUMBERs\n",
    "\n",
    "joa = Joaquin(train_data, \n",
    "              frozen=frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsf_X, *_ = train_data.get_sub_Xy('lsf')\n",
    "axes = None\n",
    "for tele in ['apo25m', 'lco25m']:\n",
    "    mask = train_stars['TELESCOPE'] == tele\n",
    "    \n",
    "    if axes is None:\n",
    "        fig, axes = simple_corner(lsf_X[mask], \n",
    "                                  color_by=train_stars['MEANFIB'][mask],\n",
    "                                  alpha=0.75, cmap=hesperia, \n",
    "                                  labels=[r'$a_{\\rm b}$', r'$b_{\\rm b}$', \n",
    "                                          r'$a_{\\rm g}$', r'$b_{\\rm g}$',\n",
    "                                          r'$a_{\\rm r}$', r'$b_{\\rm r}$'])\n",
    "    else:\n",
    "        fig, axes = simple_corner(lsf_X[mask], \n",
    "                                  color_by=train_stars['MEANFIB'][mask],\n",
    "                                  alpha=0.75, cmap=laguna, axes=axes)\n",
    "        \n",
    "fig.set_facecolor('w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Optimizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_beta = joa.init_beta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(init_beta)\n",
    "plt.ylabel('init beta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = joa.optimize(options={'maxiter': 10_000})\n",
    "# res, wrapper, ps = joa.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pars = joa.unpack_pars(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(init_beta[joa.idx_map['spec']] - fit_pars['beta'][joa.idx_map['spec']])\n",
    "plt.ylabel('init beta - fit beta')\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(init_beta[joa.idx_map['spec']], label='init')\n",
    "plt.plot(fit_pars['beta'][joa.idx_map['spec']], label='fit')\n",
    "plt.ylabel('beta')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_plx = np.exp(np.dot(joa.X, fit_pars['beta']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-0.5, 2, 128)\n",
    "plt.hist(train_stars['GAIAEDR3_PARALLAX'], \n",
    "         bins=bins);\n",
    "plt.hist(pred_plx, bins=bins)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = joa.chi(**fit_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(train_stars['GAIAEDR3_PARALLAX'], \n",
    "        pred_plx,\n",
    "        marker='o', ls='none', mew=0, ms=1.5, alpha=0.75)\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(ax.get_xlim())\n",
    "ax.set_xlabel('Gaia plx')\n",
    "ax.set_ylabel('Joaquin plx')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(train_stars['GAIAEDR3_PARALLAX'], \n",
    "        chi,\n",
    "        marker='o', ls='none', mew=0, ms=1.5, alpha=0.75)\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "# ax.set_ylim(ax.get_xlim())\n",
    "ax.set_xlabel('Gaia plx')\n",
    "ax.set_ylabel(r'$\\chi$')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(chi, bins=np.linspace(-5, 5, 64));\n",
    "for x in np.percentile(chi, [16, 84]):\n",
    "    plt.axvline(x, color='tab:blue')\n",
    "    \n",
    "plt.axvline(1, linestyle='--', color='#666666')\n",
    "plt.axvline(-1, linestyle='--', color='#666666')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.scatter(train_stars['GAIAEDR3_PARALLAX'], \n",
    "           pred_plx,\n",
    "           c=np.log(train_stars['VSCATTER']), \n",
    "           vmin=-1, vmax=4, cmap='turbo',\n",
    "           marker='o', lw=0, s=10, alpha=0.75)\n",
    "\n",
    "ax.errorbar(train_stars['GAIAEDR3_PARALLAX'], \n",
    "            pred_plx,\n",
    "            xerr=train_stars['GAIAEDR3_PARALLAX_ERROR'],\n",
    "            marker='', ls='', ecolor='#666666', \n",
    "            elinewidth=0.5, alpha=0.5)\n",
    "\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(ax.get_xlim())\n",
    "ax.set_xlabel('Gaia plx')\n",
    "ax.set_ylabel('Joaquin plx')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.scatter(train_stars['GAIAEDR3_PARALLAX'], \n",
    "           chi,\n",
    "           c=np.log(train_stars['VSCATTER']), \n",
    "           vmin=-1, vmax=4, cmap='turbo',\n",
    "           marker='o', lw=0, s=10, alpha=0.75)\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "# ax.set_ylim(ax.get_xlim())\n",
    "ax.set_xlabel('Gaia plx')\n",
    "ax.set_ylabel(r'$\\chi$')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_facecolor('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# ax.scatter(train_stars['GAIAEDR3_PARALLAX_ERROR'], \n",
    "#            chi,\n",
    "#            c=np.log(train_stars['VSCATTER']), \n",
    "#            vmin=-1, vmax=4, cmap='turbo',\n",
    "#            marker='o', lw=0, s=10, alpha=0.75)\n",
    "# ax.set_xlim(-0.01, 0.1)\n",
    "# # ax.set_ylim(ax.get_xlim())\n",
    "# ax.set_xlabel('Gaia plx error')\n",
    "# ax.set_ylabel(r'$\\chi$')\n",
    "\n",
    "# fig.tight_layout()\n",
    "# fig.set_facecolor('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Photometry / colors:\n",
    "plot_X = []\n",
    "labels = []\n",
    "\n",
    "colors = [\n",
    "    ('GAIAEDR3_PHOT_BP_MEAN_MAG', 'GAIAEDR3_PHOT_RP_MEAN_MAG'),\n",
    "    ('J', 'K'),\n",
    "    ('w1mpro', 'w3mpro'),\n",
    "    ('GAIAEDR3_PHOT_G_MEAN_MAG', 'J'),\n",
    "    ('H', 'w2mpro')\n",
    "]\n",
    "for i, (p1, p2) in enumerate(colors):\n",
    "    vals = (joa.X[:, train_data.idx_map['phot'][phot_names.index(p1)]] -\n",
    "            joa.X[:, train_data.idx_map['phot'][phot_names.index(p2)]])\n",
    "    plot_X.append(vals)\n",
    "    \n",
    "    lbl1 = p1\n",
    "    if p1 in phot_to_label:\n",
    "        lbl1 = phot_to_label[p1]\n",
    "    \n",
    "    lbl2 = p2\n",
    "    if p2 in phot_to_label:\n",
    "        lbl2 = phot_to_label[p2]\n",
    "    \n",
    "    lbl = f\"{lbl1} $-$ {lbl2}\"\n",
    "    labels.append(lbl)\n",
    "    \n",
    "plot_X = np.array(plot_X).T\n",
    "\n",
    "fig, axes, cb = simple_corner(\n",
    "    plot_X, \n",
    "    color_by=chi,\n",
    "    colorbar=True,\n",
    "    labels=labels,\n",
    "    vmin=-3, vmax=3, s=8,\n",
    "    alpha=0.75, cmap='RdBu')\n",
    "cb.ax.set_aspect(40)\n",
    "\n",
    "fig.set_facecolor('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Housekeeping:\n",
    "plot_X = train_data.get_sub_Xy(['lsf'])[0]\n",
    "labels = [r'$a_{\\rm b}$', r'$b_{\\rm b}$', \n",
    "          r'$a_{\\rm g}$', r'$b_{\\rm g}$',\n",
    "          r'$a_{\\rm r}$', r'$b_{\\rm r}$']\n",
    "\n",
    "fig, axes, cb = simple_corner(\n",
    "    plot_X, \n",
    "    color_by=chi,\n",
    "    colorbar=True,\n",
    "    labels=labels,\n",
    "    vmin=-3, vmax=3, s=8,\n",
    "    alpha=0.75, cmap='RdBu')\n",
    "cb.ax.set_aspect(40)\n",
    "\n",
    "fig.set_facecolor('w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = joa.init_beta(L2_ivar=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = [0., 0.5] + list(beta)\n",
    "joa(p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = jax.value_and_grad(joa.__call__)\n",
    "obj = jax.value_and_grad(neg_ln_posterior, argnums=[3, 4, 5])\n",
    "def wrapper(*args, **kwargs):\n",
    "    val, grads = obj(*args, **kwargs)\n",
    "    return val, jnp.concatenate([g.reshape(-1) for g in grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(p0)\n",
    "val, grad = wrapper(joa.X, joa.y, joa.y_ivar, \n",
    "                    0., 0.5, beta, joa.L2_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.dot(np.random.random(size=(10, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(beta[dm.idx_map['lsf']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(phot_names, beta[dm.idx_map['phot']])\n",
    "plt.xticks(rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 3))\n",
    "plt.plot(beta[dm.idx_map['spec']])\n",
    "plt.xlim(800, 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(all_spec_mask)[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix = np.arange(8575, dtype='f8')\n",
    "wvln = 10 ** (star_hdul[1].header['CRVAL1'] +\n",
    "              np.arange(star_hdul[1].header['NAXIS1']) * star_hdul[1].header['CDELT1'])\n",
    "ln_wvln = np.log(wvln)\n",
    "flux = star_hdul[1].data\n",
    "err = star_hdul[2].data\n",
    "\n",
    "mask = (flux == 0 ) | (err > (3 * np.median(err)))\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(wvln[~mask], flux[~mask], marker='', drawstyle='steps-mid')\n",
    "# plt.plot(wvln[mask], flux[mask], marker='o', ls='none', color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_flux = nufft_lowpass(ln_wvln, flux, \n",
    "                         fcut=0.5 * 22500, bad_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(wvln, flux, marker='', drawstyle='steps-mid')\n",
    "plt.plot(wvln, new_flux, \n",
    "         marker='', drawstyle='steps-mid', color='tab:blue')\n",
    "plt.plot(wvln[mask], flux[mask], \n",
    "         marker='.', ls='none', color='r')\n",
    "plt.xlim(15500+500, 15600+500)\n",
    "plt.axhline(1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for star in stars[:4]:\n",
    "    star_hdul = get_aspcapstar(star)\n",
    "    lsf_hdul = get_lsf(star)\n",
    "    \n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(lsf_hdul[0].data[:, 7], \n",
    "             marker='', drawstyle='steps-mid', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adrian conda base",
   "language": "python",
   "name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
